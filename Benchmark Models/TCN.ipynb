{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import time\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=4, kernel_size=2, stride=1, dilation=1)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(4)\n",
    "        self.conv2 = nn.Conv1d(in_channels=4, out_channels=8, kernel_size=2, stride=1, dilation=2)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(8)\n",
    "        self.conv3 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=2, stride=1, dilation=4)\n",
    "        self.linear = nn.Linear(16 * 73, 12)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 16 * 73)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def parameter_count(self):\n",
    "        par = list(self.parameters())\n",
    "        s = sum([np.prod(list(d.size())) for d in par])\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('../dataset/pems.npy', allow_pickle=True).item()\n",
    "x, y = dataset['X'], dataset['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(x.shape[0], x.shape[2])\n",
    "scaler = preprocessing.StandardScaler().fit(x)\n",
    "x = scaler.transform(x)\n",
    "x = x.reshape(x.shape[0], 1, x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "y_train = y_train.reshape(y_train.shape[0], y_train.shape[2])\n",
    "y_test = y_test.reshape(y_test.shape[0], y_test.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Data.TensorDataset(x_train, y_train)\n",
    "loader = Data.DataLoader(dataset=dataset_train, batch_size=256, shuffle=True, num_workers=2)\n",
    "\n",
    "batch_num = 0\n",
    "for step, (batch_x, batch_y) in enumerate(loader):\n",
    "    batch_num += 1\n",
    "print('%d batches' % batch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = choose_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, y, net, criterion=nn.MSELoss(), clips=12, suppress_output=False):\n",
    "    y_hat = net(x.to(device))\n",
    "    y_hat = y_hat[:, :clips]\n",
    "    y = y[:, :clips].to(device)\n",
    "    loss = criterion(y_hat, y)\n",
    "    RMSE = loss.item() ** 0.5\n",
    "    MAPE = compute_MAPE(y, y_hat)\n",
    "    MAE = compute_MAE(y, y_hat)\n",
    "    if suppress_output == False:\n",
    "        print('samples: %d - %d\\ntime clips: %d\\nRMSE: %.2f\\nMAPE: %.2f%%\\nMAE: %.2f' % (y_hat.shape[0], y.shape[0], clips, RMSE, MAPE, MAE))\n",
    "    return RMSE, MAPE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(rounds=20, epochs=150, lr=0.001, weight_decay=0.001, clips=[3, 6, 12], criterion=nn.MSELoss()):\n",
    "    # init\n",
    "    criterions = ['RMSE', 'MAPE', 'MAE']\n",
    "    columns = []\n",
    "    for clip in clips:\n",
    "        for each in criterions:\n",
    "            columns.append('%s_%d' % (each, clip))\n",
    "    df = []\n",
    "    # multiple runs\n",
    "    for cur_round in range(1, rounds + 1, 1):\n",
    "        # init\n",
    "        net = TCN().to(device)        \n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        train_losses, test_losses = [], []\n",
    "        # train\n",
    "        for epoch in range(epochs):\n",
    "            t_start = time.time()\n",
    "            running_RMSE, running_MAPE = 0, 0\n",
    "\n",
    "            for step, (batch_x, batch_y) in enumerate(loader):\n",
    "                input_x = batch_x.to(device)\n",
    "                y = batch_y.to(device)  \n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output_data = net(input_x)\n",
    "                loss = criterion(output_data, y)\n",
    "                MAPE = compute_MAPE(output_data, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_RMSE += loss.item() ** 0.5\n",
    "                running_MAPE += MAPE\n",
    "            train_losses.append(running_RMSE / batch_num)\n",
    "\n",
    "            test_losses.append(criterion(net(x_test.to(device)), y_test.to(device)).item() ** 0.5)\n",
    "            t_end = time.time()\n",
    "\n",
    "            print('\\rround=%02d, epoch=%d, RMSE=%.2f, MAPE=%.2f%%, time=%.2fs per epoch      ' \\\n",
    "                  % (cur_round, epoch+1, running_RMSE / batch_num, running_MAPE / batch_num, t_end-t_start), end='')\n",
    "        print()\n",
    "        #evaluate\n",
    "        evaluation_clip = []\n",
    "        for clip in clips:\n",
    "            RMSE, MAPE, MAE = evaluate(x_test, y_test, net, criterion, clips=clip, suppress_output=True)\n",
    "            eva = [RMSE, MAPE, MAE]\n",
    "            evaluation_clip += eva\n",
    "        df.append(evaluation_clip)\n",
    "    df = pd.DataFrame(df, columns=columns)\n",
    "    df.index = np.arange(1, rounds+1, 1)\n",
    "    return df, train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train_losses, test_losses = run(rounds=10, epochs=150, lr=0.006, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloss = pd.DataFrame({'epoch': np.arange(1, len(train_losses)+1, 1), 'train_loss': train_losses, 'test_loss': test_losses})\n",
    "sns.lineplot(x='epoch', y='train_loss', data=dloss, label='train loss')\n",
    "sns.lineplot(x='epoch', y='test_loss', data=dloss, label='test loss')\n",
    "plt.ylabel('value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Multiple Run Results/TCN_10.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
